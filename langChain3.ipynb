{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build an Agent"
      ],
      "metadata": {
        "id": "Iigirb15Vf5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> LangChain supports the creation of agents, or systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling.\n",
        "\n",
        "In this tutorial we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it.\n",
        "\n"
      ],
      "metadata": {
        "id": "JOnz0HF5Vka1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-2aWliaVQyL",
        "outputId": "054d933e-7577-45a3-a228-18be3e8b99bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.11-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting langgraph-checkpoint-sqlite\n",
            "  Downloading langgraph_checkpoint_sqlite-2.0.11-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.72)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (3.12.15)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (0.3.27)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (2.32.3)\n",
            "Collecting aiosqlite>=0.20 (from langgraph-checkpoint-sqlite)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting sqlite-vec>=0.1.6 (from langgraph-checkpoint-sqlite)\n",
            "  Downloading sqlite_vec-0.1.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux1_x86_64.whl.metadata (198 bytes)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.20.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.11/dist-packages (from aiosqlite>=0.20->langgraph-checkpoint-sqlite) (4.14.1)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.12)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.0.42)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.23.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.4-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_tavily-0.2.11-py3-none-any.whl (26 kB)\n",
            "Downloading langgraph_checkpoint_sqlite-2.0.11-py3-none-any.whl (31 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlite_vec-0.1.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux1_x86_64.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sqlite-vec, ormsgpack, aiosqlite, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph-checkpoint-sqlite, langgraph, langchain-tavily\n",
            "Successfully installed aiosqlite-0.21.0 langchain-tavily-0.2.11 langgraph-0.6.4 langgraph-checkpoint-2.1.1 langgraph-checkpoint-sqlite-2.0.11 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 ormsgpack-1.10.0 sqlite-vec-0.1.6\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langgraph langchain-tavily langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfxvJB1yWASD",
        "outputId": "a232586d-c433-4d06-e84d-6f2911e39b86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea6IhCygWGaV",
        "outputId": "00352777-10fe-413d-b3f6-4f393a55ad62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "search = TavilySearch(max_results=2)\n",
        "search_results = search.invoke(\"What is the weather in Jalandhar\")\n",
        "print(search_results)\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mqcSFJMX9Mp",
        "outputId": "95fd1ba6-f019-4623-9d68-f02b1ce05410"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What is the weather in Jalandhar', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in Jalandhar', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Jalandhar', 'region': 'Punjab', 'country': 'India', 'lat': 31.3256, 'lon': 75.5792, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1754869541, 'localtime': '2025-08-11 05:15'}, 'current': {'last_updated_epoch': 1754869500, 'last_updated': '2025-08-11 05:15', 'temp_c': 27.5, 'temp_f': 81.5, 'is_day': 0, 'condition': {'text': 'Partly Cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 4.7, 'wind_kph': 7.6, 'wind_degree': 145, 'wind_dir': 'SE', 'pressure_mb': 1002.0, 'pressure_in': 29.58, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 81, 'cloud': 45, 'feelslike_c': 31.4, 'feelslike_f': 88.4, 'windchill_c': 27.5, 'windchill_f': 81.5, 'heatindex_c': 31.4, 'heatindex_f': 88.4, 'dewpoint_c': 23.9, 'dewpoint_f': 75.0, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.0, 'gust_mph': 8.9, 'gust_kph': 14.4}}\", 'score': 0.9720501, 'raw_content': None}, {'url': 'https://timesofindia.indiatimes.com/weather/jalandhar-weather-forecast-today/144001', 'title': 'Jalandhar Weather Forecast 10 Aug 2025 - The Times of India', 'content': \"Today's Weather in Jalandhar: In Jalandhar today, the weather is expected to be Mostly Cloudy with a maximum temperature of 34°C and a minimum of 27°C . Sunrise in Jalandhar is set for 05:49 AM and sunset at 07:15 PM Atmospheric pressure will be around 100.1 kPa with humidity at 81.\", 'score': 0.96110183, 'raw_content': None}], 'response_time': 1.71}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[google-genai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z43whyuUX_Y6",
        "outputId": "69905a8a-249a-44ff-daed-ed8402804ff6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfDpyCExYMzH",
        "outputId": "6ae2494a-7b7b-4ac6-fc2d-2190571c77c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for Google Gemini: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Hi!\"\n",
        "response = model.invoke([{\"role\": \"user\", \"content\": query}])\n",
        "response.text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2nmdrzcWYPXZ",
        "outputId": "f68549dc-3ce0-49b1-a03c-0106e6a4214f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now see what it is like to enable this model to do tool calling. In order to enable that we use .bind_tools to give the language model knowledge of these tools"
      ],
      "metadata": {
        "id": "ofnNjj0MYgzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_tools = model.bind_tools(tools)"
      ],
      "metadata": {
        "id": "JJqZQVwKYUGj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now call the model. Let's first call it with a normal message, and see how it responds. We can look at both the content field as well as the tool_calls field.\n",
        "\n"
      ],
      "metadata": {
        "id": "2iNLImFxYrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Hi!\"\n",
        "response = model_with_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
        "\n",
        "print(f\"Message content: {response.text()}\\n\")\n",
        "print(f\"Tool calls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjKIPdz1Yj3P",
        "outputId": "9febd823-b86d-43f5-b4dc-0d89a49c29e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message content: Hello! How can I help you today?\n",
            "\n",
            "Tool calls: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Search for the weather in SF\"\n",
        "response = model_with_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
        "\n",
        "print(f\"Message content: {response.text()}\\n\")\n",
        "print(f\"Tool calls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He0uWRZmYuAq",
        "outputId": "185c5e8d-a8d4-455c-9843-6ee7463b0099"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message content: \n",
            "\n",
            "Tool calls: [{'name': 'tavily_search', 'args': {'query': 'weather in SF'}, 'id': '45b4eaa8-9cd8-490e-9b58-4b98df094358', 'type': 'tool_call'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent."
      ],
      "metadata": {
        "id": "yUGF6L47Y9az"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2tiljkL6Y04i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(model, tools)"
      ],
      "metadata": {
        "id": "NSOhHkT1asB_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = {\"role\": \"user\", \"content\": \"Hi!\"}\n",
        "response = agent_executor.invoke({\"messages\": [input_message]})\n",
        "\n",
        "for message in response[\"messages\"]:\n",
        "    message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QOPO13TasxV",
        "outputId": "8f9785b3-9a0d-464c-b5d4-b45fa7981bd5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = {\"role\": \"user\", \"content\": \"Search for the weather in SF\"}\n",
        "response = agent_executor.invoke({\"messages\": [input_message]})\n",
        "\n",
        "for message in response[\"messages\"]:\n",
        "    message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agfcaDSpaz6y",
        "outputId": "53aa7e5c-9fc7-4a86-b7ef-60c118650bb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Search for the weather in SF\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (9d85f8b0-6c24-4981-81e3-eae128f72543)\n",
            " Call ID: 9d85f8b0-6c24-4981-81e3-eae128f72543\n",
            "  Args:\n",
            "    query: weather in SF\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"weather in SF\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Weather in San Francisco\", \"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1754870370, 'localtime': '2025-08-10 16:59'}, 'current': {'last_updated_epoch': 1754869500, 'last_updated': '2025-08-10 16:45', 'temp_c': 19.4, 'temp_f': 66.9, 'is_day': 1, 'condition': {'text': 'Partly Cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 12.1, 'wind_kph': 19.4, 'wind_degree': 255, 'wind_dir': 'WSW', 'pressure_mb': 1014.0, 'pressure_in': 29.95, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 71, 'cloud': 25, 'feelslike_c': 19.4, 'feelslike_f': 66.9, 'windchill_c': 16.1, 'windchill_f': 61.0, 'heatindex_c': 16.1, 'heatindex_f': 61.0, 'dewpoint_c': 13.8, 'dewpoint_f': 56.8, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 19.8, 'gust_kph': 31.9}}\", \"score\": 0.9741099, \"raw_content\": null}, {\"url\": \"https://en.climate-data.org/south-america/colombia/cundinamarca/san-francisco-49889/t/august-8/\", \"title\": \"Weather San Francisco in August 2025\", \"content\": \"Are you planning a holiday with hopefully nice weather in San Francisco in August 2025? ... 10. August, 20 °C | 68 °F, 25 °C | 77 °F, 17 °C | 62 °F, 21.6 mm | 0.9\", \"score\": 0.9486564, \"raw_content\": null}], \"response_time\": 1.96}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The current weather in San Francisco, California, United States of America, as of 2025-08-10 16:45 (local time 16:59), is partly cloudy with a temperature of 19.4°C (66.9°F). The wind is blowing from the WSW at 12.1 mph (19.4 kph), and the humidity is 71%. It feels like 19.4°C (66.9°F).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in agent_executor.stream({\"messages\": [input_message]}, stream_mode=\"values\"):\n",
        "    step[\"messages\"][-1].pretty_print()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfwG-9Fra7bP",
        "outputId": "bf136b40-7da9-41f3-cadf-6d22bd68c5d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Search for the weather in SF\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (bcdcccaa-4608-4406-8b28-bbd3395e6942)\n",
            " Call ID: bcdcccaa-4608-4406-8b28-bbd3395e6942\n",
            "  Args:\n",
            "    query: weather in SF\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"weather in SF\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Weather in San Francisco\", \"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1754870370, 'localtime': '2025-08-10 16:59'}, 'current': {'last_updated_epoch': 1754869500, 'last_updated': '2025-08-10 16:45', 'temp_c': 19.4, 'temp_f': 66.9, 'is_day': 1, 'condition': {'text': 'Partly Cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 12.1, 'wind_kph': 19.4, 'wind_degree': 255, 'wind_dir': 'WSW', 'pressure_mb': 1014.0, 'pressure_in': 29.95, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 71, 'cloud': 25, 'feelslike_c': 19.4, 'feelslike_f': 66.9, 'windchill_c': 16.1, 'windchill_f': 61.0, 'heatindex_c': 16.1, 'heatindex_f': 61.0, 'dewpoint_c': 13.8, 'dewpoint_f': 56.8, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 19.8, 'gust_kph': 31.9}}\", \"score\": 0.9741099, \"raw_content\": null}, {\"url\": \"https://en.climate-data.org/south-america/colombia/cundinamarca/san-francisco-49889/t/august-8/\", \"title\": \"Weather San Francisco in August 2025\", \"content\": \"Are you planning a holiday with hopefully nice weather in San Francisco in August 2025? ... 10. August, 20 °C | 68 °F, 25 °C | 77 °F, 17 °C | 62 °F, 21.6 mm | 0.9\", \"score\": 0.9486564, \"raw_content\": null}], \"response_time\": 1.35}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The weather in San Francisco is partly cloudy with a temperature of 66.9°F (19.4°C). The wind is blowing from the WSW at 12.1 mph, and the humidity is 71%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step, metadata in agent_executor.stream(\n",
        "    {\"messages\": [input_message]}, stream_mode=\"messages\"\n",
        "):\n",
        "    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
        "        print(text, end=\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJlRx_KLbL43",
        "outputId": "a8fa9edc-8039-49d4-e39e-79b95f29bc89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in San Francisco, California on August 10, 2025, at 4:45 PM is partly cloudy with a temperature of 66.9°F (19.4°C). The wind is| from the WSW at 12.1 mph (19.4 kph) with gusts up to 19.8 mph (31.9 kph). Humidity is 71%, and there is no precipitation.| The pressure is 29.95 in (1014.0 mb).|"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding in memory**"
      ],
      "metadata": {
        "id": "egqi1_wDbXng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ],
      "metadata": {
        "id": "RpcmVh_NbTg3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ],
      "metadata": {
        "id": "wAgO9wrKbf9s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = {\"role\": \"user\", \"content\": \"Hi, I'm Bob!\"}\n",
        "for step in agent_executor.stream(\n",
        "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX7bXVJTbiRk",
        "outputId": "c15db87f-eefe-4c01-e4fc-697e56c6ff66"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi, I'm Bob!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Bob! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
        "for step in agent_executor.stream(\n",
        "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWpzg-sebkfm",
        "outputId": "56df7fd2-5523-4f90-a8a0-080ab46b24f6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What's my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I'm sorry, I don't have access to past conversations and cannot recall your name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avIsPCEKbndz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}